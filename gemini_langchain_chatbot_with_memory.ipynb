{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061e5402",
   "metadata": {},
   "source": [
    "# ðŸ¤– LangChain + Gemini Chatbot with Memory\n",
    "This notebook demonstrates the use of Google Gemini with LangChain to build a memory-enabled chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78927d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74b5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import additional libraries\n",
    "import requests\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory, BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448b13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample direct API call to Google Gemini endpoint\n",
    "url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
    "api_key = \"AIzaSyAOOydOEI3iD99zf0M68ILXZJtWXjbELTQ\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"parts\": [\n",
    "                {\"text\": \"Explain how AI works\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{url}?key={api_key}\", headers=headers, json=data)\n",
    "# This sends a sample request and retrieves a response\n",
    "# print(response.status_code)\n",
    "# print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93cb0380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize LangChain's ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=api_key,\n",
    "    convert_system_message_to_human=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc7d79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Output parser to clean response\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Parsing a simple greeting to test the setup\n",
    "parser.invoke(model.invoke(\"HI\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338d6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup session memory store\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ee3497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing first session ID\n",
    "config = {\"configurable\" : {\"session_id\" :\"firstchat\"}}\n",
    "memory_model = RunnableWithMessageHistory(model , get_session_history)\n",
    "\n",
    "response1 = memory_model.invoke([HumanMessage(content=\"hey how ara you , im Gihan Lakmal\")] , config=config).content\n",
    "response2 = memory_model.invoke([HumanMessage(content=\"can u say my Name again please\")] , config=config).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092df301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing second session ID\n",
    "config = {\"configurable\" : {\"session_id\" :\"secondchat\"}}\n",
    "response1 = memory_model.invoke([HumanMessage(content=\"hey how ara you , im Savindu perera\")] , config=config).content\n",
    "response2 = memory_model.invoke([HumanMessage(content=\"can u say my Name again please\")] , config=config).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48462bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Rechecking first session ID\n",
    "config = {\"configurable\" : {\"session_id\" :\"firstchat\"}}\n",
    "response3 = memory_model.invoke([HumanMessage(content=\"can u say my Name again please\")] , config=config).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b7966e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Gihan Lakmal! It's nice to meet you. I'm ready to help you with any questions you have. Just let me know what you need. ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a chain with a system prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\" , \"You are a helpfull Assistent. Answer the all questions to the best of your ability\") , \n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "print(chain.invoke({\"message\" : [\"hi im Gihan Lakmal\"] }).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ecf2eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Gihan Lakmal! I understand you're saying that 2 + 2 = 3. \n",
      "\n",
      "While I appreciate your input, in standard mathematics, 2 + 2 always equals 4. Perhaps you were joking, or maybe thinking about a different mathematical system or a trick question?\n",
      "\n",
      "If you'd like to explore some other interesting math concepts or puzzles, let me know!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Gihan Lakmal, I remember your name.\n",
      "\n",
      "And you said that 2 + 2 = 3.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Memory-aware chat chain\n",
    "memory_model = RunnableWithMessageHistory(chain , get_session_history)\n",
    "config = {\"configurable\" :{\"session_id\": \"thirdchat\"}}\n",
    "\n",
    "response = memory_model.invoke(\n",
    "    [HumanMessage(content=\"hey im Gihan Lakmal and 2+2 is 3 \")] , \n",
    "    config=config\n",
    ")\n",
    "print(response.content)\n",
    "\n",
    "# Testing memory for the same session\n",
    "response = memory_model.invoke(\n",
    "    [HumanMessage(content=\"Do u remember my name? and 2+2 , which i said the answer?\")] , \n",
    "    config=config\n",
    ")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b71e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2df20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5fec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a710e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315250ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed28b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
